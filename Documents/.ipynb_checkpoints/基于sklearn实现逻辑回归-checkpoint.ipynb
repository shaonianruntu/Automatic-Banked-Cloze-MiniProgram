{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集accuracy: 0.993464052288\n",
      "测试集accuracy:  0.962454873646\n",
      "测试集AUC: 0.991765957543\n"
     ]
    }
   ],
   "source": [
    "# coding=utf8\n",
    "# 调用sklearn实现逻辑回归对短文本（垃圾短信）分类\n",
    "#  Copyright 木豆\n",
    "#  2017-11-6\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import jieba\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "def create_vocab_dict(dataSet):\n",
    "    vocab_dict = {}    \n",
    "    for document in dataSet:\n",
    "        for term in document:\n",
    "           if term in vocab_dict:\n",
    "              vocab_dict[term] += 1\n",
    "           else:\n",
    "              vocab_dict[term] = 1\n",
    "    return vocab_dict\n",
    "\n",
    "def BOW_feature(vocabList, inputSet):\n",
    "    returnVec = [0]*len(vocabList)\n",
    "    for word in inputSet:\n",
    "        if word in vocabList:\n",
    "            returnVec[vocabList.index(word)] += 1\n",
    "    return returnVec\n",
    "\n",
    "def get_dataset(data_path):\n",
    "    text_list = []\n",
    "    labels = []\n",
    "    for line in open(data_path, \"r\"):     \n",
    "        arr = line.rstrip().split('\\t')\n",
    "        if len(arr) < 3:\n",
    "            continue\n",
    "        label = arr[0]\n",
    "        text = arr[2]\n",
    "        text_list.append(list(text.split()))\n",
    "        labels.append(float(label))\n",
    "    return text_list, labels    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # 读取数据\n",
    "    train_file_path = 'mudou_spam.train'\n",
    "    test_file_path = 'mudou_spam.test'\n",
    "    train_data, train_label = get_dataset(train_file_path)\n",
    "    test_data, test_label = get_dataset(test_file_path)\n",
    "    \n",
    "    # 构造词典\n",
    "    min_freq = 5\n",
    "    vocab_dict = create_vocab_dict(train_data)\n",
    "    sorted_vocab_list= sorted(vocab_dict.iteritems(), key=lambda d:d[1], reverse = True)    \n",
    "    vocab_list = [  v[0]  for v  in sorted_vocab_list if int(v[1]) > min_freq ]\n",
    " \n",
    "    # 生成文本的词袋（BOW）特征\n",
    "    train_X = []\n",
    "    for one_msg  in train_data:\n",
    "        train_X.append(BOW_feature(vocab_list, one_msg))\n",
    "        \n",
    "    test_X = []\n",
    "    for one_msg  in test_data:\n",
    "        test_X.append(BOW_feature(vocab_list, one_msg))\n",
    "        \n",
    "    # 训练模型\n",
    "    model = LogisticRegression()\n",
    "    model.fit(train_X, train_label)\n",
    "    pred = model.predict(test_X)\n",
    "\n",
    "    # 模型评估\n",
    "    accuracy_train = model.score(train_X, train_label)\n",
    "    print '训练集accuracy:',accuracy_train\n",
    "    accuracy_test = model.score(test_X, test_label)\n",
    "    print '测试集accuracy: ',accuracy_test\n",
    "\n",
    "    predict_prob_y = model.predict_proba(test_X)[:,1]\n",
    "    test_auc = metrics.roc_auc_score(test_label,predict_prob_y)\n",
    "    print '测试集AUC:',test_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

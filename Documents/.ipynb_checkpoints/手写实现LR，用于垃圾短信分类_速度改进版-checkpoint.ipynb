{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print('训练集accuracy:',accuracy_train)? (<ipython-input-1-97979daff33f>, line 140)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-97979daff33f>\"\u001b[1;36m, line \u001b[1;32m140\u001b[0m\n\u001b[1;33m    print '训练集accuracy:',accuracy_train\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print('训练集accuracy:',accuracy_train)?\n"
     ]
    }
   ],
   "source": [
    "# coding=utf8\n",
    "# 手写逻辑回归，并实现垃圾短信分类\n",
    "#  基于mini-batch GD，不考虑正则\n",
    "#  Copyright 木豆\n",
    "#  2017-11-6\n",
    "import os\n",
    "import sys\n",
    "import jieba\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from random import randrange\n",
    "import time\n",
    "\n",
    "class logistic_regression():\n",
    "    \"\"\"\n",
    "       手写逻辑回归，用于二分类。\n",
    "       注意事项：\n",
    "           1）sklearn自带的lr可以做多分类，这里我们实现的版本只能做二分类\n",
    "           2）这里我们支持的label是1,0。如果您的label是1,-1，请先通过预处理进行转换\n",
    "    \"\"\"\n",
    "    def fit(self, train_X_in, train_Y, learning_rate=0.5, batch_size=20, eps=1e-3):   \n",
    " \n",
    "        case_cnt, feature_cnt = np.array(train_X_in).shape\n",
    "        self.theta = np.zeros([feature_cnt + 1,1])\n",
    "        train_X = np.c_[train_X_in, np.ones(case_cnt,)]\n",
    "        \n",
    "        step = 0\n",
    "        max_iteration_times = sys.maxint\n",
    "        past_best_likelihood = -sys.maxint - 1\n",
    "        past_step = 0\n",
    "        stay_times = 0\n",
    "        X = train_X.T\n",
    "        while step < max_iteration_times:\n",
    "            for b in range(0, case_cnt, batch_size):  \n",
    "                pred = 1.0/(1 + np.exp(-self.theta.T.dot(X[:,b : b + batch_size])))   \n",
    "                self.theta = self.theta + learning_rate * 1.0/case_cnt*\\\n",
    "                         (train_Y[b : b + batch_size] - pred).dot(X[:, b : b + batch_size].T).T         \n",
    "                      \n",
    "            pred = 1.0/(1 + np.exp(-self.theta.T.dot(X)))       \n",
    "            likelihood = 1.0/case_cnt*sum((train_Y * np.log(pred) + \\\n",
    "                       (1 - train_Y)* np.log(1 - pred)).flatten()) \n",
    "            if   likelihood > past_best_likelihood + eps:\n",
    "                past_best_likelihood = likelihood\n",
    "                past_step = step   \n",
    "            elif  step - past_step >= 20:\n",
    "                sys.stderr.write(\"training finished. total step %s: %.6f\\n\" % (step, likelihood))\n",
    "                break   \n",
    "            if step % 1000 == 0:\n",
    "                sys.stderr.write(\"step %s: %.6f\\n\" % (step, likelihood))             \n",
    "            step += 1    \n",
    "        return  1\n",
    "     \n",
    "    def predict_proba(self, X):\n",
    "        case_cnt = X.shape[0]\n",
    "        X = np.c_[X, np.ones(case_cnt,)]\n",
    "        return 1. / (1 + np.exp(-self.theta.T.dot(X.T)))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        case_cnt = X.shape[0]\n",
    "        X = np.c_[X, np.ones(case_cnt,)]\n",
    "        prob = 1. / (1 + np.exp(-self.theta.T.dot(X.T)))\n",
    "        return (prob >= 0.5).astype(np.int32).flatten()\n",
    "    \n",
    "    def score(self, X, label):\n",
    "       \"\"\" Returns the mean accuracy on the given test data and labels \"\"\"\n",
    "       pred = self.predict(X)\n",
    "       return sum((pred == label).astype(np.int32).flatten()) * 1.0 / pred.shape[0]\n",
    "    \n",
    "def create_vocab_dict(dataSet):\n",
    "    vocab_dict = {}    \n",
    "    for document in dataSet:\n",
    "        for term in document:\n",
    "           if term in vocab_dict:\n",
    "              vocab_dict[term] += 1\n",
    "           else:\n",
    "              vocab_dict[term] = 1\n",
    "    return vocab_dict\n",
    "\n",
    "def BOW_feature(vocabList, inputSet):\n",
    "    returnVec = [0]*len(vocabList)\n",
    "    for word in inputSet:\n",
    "        if word in vocabList:\n",
    "            returnVec[vocabList.index(word)] += 1\n",
    "    return returnVec\n",
    "\n",
    "def get_dataset(data_path):\n",
    "    text_list = []\n",
    "    labels = []\n",
    "    for line in open(data_path, \"r\"):     \n",
    "        arr = line.rstrip().split('\\t')\n",
    "        if len(arr) < 3:\n",
    "            continue\n",
    "        \n",
    "        # 把标签从(1,-1)改为(1,0)    \n",
    "        if int(arr[0]) == 1:\n",
    "            label = arr[0]\n",
    "        elif int(arr[0]) == -1:\n",
    "            label = 0\n",
    "        else:   # illegal label\n",
    "            continue        \n",
    "        text = arr[2]\n",
    "        text_list.append(list(text.split()))\n",
    "        labels.append(float(label))\n",
    "    return text_list, labels    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # 读取数据\n",
    "    train_file_path = 'mudou_spam.train'\n",
    "    test_file_path = 'mudou_spam.test'\n",
    "    train_data, train_label = get_dataset(train_file_path)\n",
    "    test_data, test_label = get_dataset(test_file_path)\n",
    "    \n",
    "    # 构造词典\n",
    "    min_freq = 5\n",
    "    vocab_dict = create_vocab_dict(train_data)\n",
    "    sorted_vocab_list= sorted(vocab_dict.iteritems(), key=lambda d:d[1], reverse = True)    \n",
    "    vocab_list = [ v[0]  for v  in sorted_vocab_list if int(v[1]) > min_freq ]\n",
    " \n",
    "    # 生成文本的词袋（BOW）特征\n",
    "    train_X = []\n",
    "    for one_msg  in train_data:\n",
    "        train_X.append(BOW_feature(vocab_list, one_msg))\n",
    "        \n",
    "    test_X = []\n",
    "    for one_msg  in test_data:\n",
    "        test_X.append(BOW_feature(vocab_list, one_msg))\n",
    "        \n",
    "    test_label = np.array(test_label)\n",
    "    train_label = np.array(train_label)\n",
    "    train_X = np.array(train_X)    \n",
    "    test_X = np.array(test_X)    \n",
    "    \n",
    "    # 训练模型\n",
    "    model = logistic_regression() \n",
    "    model.fit(train_X, train_label, 0.6, 100, 1e-4)\n",
    "     \n",
    "    # 模型评估\n",
    "    accuracy_train = model.score(train_X, train_label)\n",
    "    print '训练集accuracy:',accuracy_train\n",
    "    accuracy_test = model.score(test_X, test_label)\n",
    "    print '测试集accuracy: ',accuracy_test\n",
    "    \n",
    "    # pred = model.predict(test_X)     \n",
    "    predict_prob_y = model.predict_proba(test_X)\n",
    "    test_auc = metrics.roc_auc_score(test_label.flatten(), predict_prob_y.flatten())\n",
    "    print '测试集AUC:',test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.zeros([10, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
